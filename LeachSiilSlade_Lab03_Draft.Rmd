---
title: "Lab 3 - Reducing Crime"
author: "Clayton G. Leach, Karl I. Siil, Timothy S. Slade"
date: "July 23, 2018"
mainfont: 'Arial'
header-includes:
- \usepackage{caption}
- \usepackage{hhline}
- \usepackage{footnote}
- \usepackage{array}
- \usepackage{booktabs}
#- \usepackage{minted}
output: 
  pdf_document: 
    latex_engine: xelatex
    #pandoc_args: "--pdf-engine-opt=-shell-escape"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(here) # TS: Added this to handle the user-agnostic run.
library(car)
library(stargazer)
```

# Introduction

Our client is running for office in the state of North Carolina (NC). Her campaign commissioned us to research the determinants of crime in NC to help her develop her platform regarding crime-related policy initiatives at the level of local government. This report explores a 1994 dataset from Cornwell & Trumball that provides county-level economic, demographic, and crime data. Our analysis describes the dataset, presents some initial summary statistics, develops three plausible models of the determinants of crime, and evaluates their accuracy and utility.

# Initial Exploratory Data Analysis (EDA)

```{r data_import, echo = FALSE, results = "hide"}
#here::dr_here() # TS: Use on first run to see why it fails on your machine, if it does.
here::here() # TS: Use when all set up, so we can mask the output.
#crime_raw <- read_csv('../crime_v2.csv', # TS: Commented out b/c using "here()" don't need ../
crime_raw <- read_csv('crime_v2.csv', col_types = cols( prbconv = col_double()))
problems(crime_raw) # TS: To comment out once we're ready to generate our draft report.
crime_raw[97, ]
```

## Missing Values

```{r drop_blank_rows}
# KS: Rows with no data
crime_na <- crime_raw %>% filter_all(any_vars(!is.na(.)))
# KS: Row with one back tick
crime_na %>% filter_all(any_vars(is.na(.))) %>% select(which(!is.na(.)))
crime_na <- crime_na %>% filter_all(all_vars(!is.na(.)))
```

Upon loading the data, we examine the `r nrow(crime_raw %>% filter_all(any_vars(is.na(.))))` rows that are missing data, finding that 5 are entirely blank and 1 contains only a backtick. We eliminate those to generate our working dataset.

```{r summary, include=FALSE}
crime_na %>% summary() # TS: I think we'll want to suppress this snippet in the draft we turn in...added include = FALSE
```

## Erroneous Duplicate Records

```{r find_dup_county}
crime_na %>% count(county) %>% filter(n > 1) # county 193 is an exact duplicate 
crime_na %>% filter(county == 193)
```

Continuing our QC, we note that one of the counties' records has been duplicated exactly. We therefore drop the duplicate record from our dataset.

```{r drop_dup_county}
crime_na <- crime_na %>% filter(!duplicated(.))
```

## Plausibility Checks for Variables

Three of our key variables of interest (`prbarr`, `prbconv`, and `prbpris`) represent probabilities and should therefore theoretically be in the range of 0:1.

```{r prob_beyond_range}
# look at weird 'probability' variables.
non_prob <- crime_na %>%
  filter(!between(prbarr, 0, 1) | !between(prbconv, 0, 1) | !between(prbpris, 0, 1))
```

Examining the data, we find `r nrow(non_prob)` counties have values for the "probability" variables that are outside of the expected range. In each case, it is either `prbconv` (10 records) or `prbarr` (1 record) that fall outside the range.

Per the notes accompanying our data, _The probability of conviction is proxied by the ratio of convictions to arrests..._ Given that definition, if not all suspects arrested are convicted, `prbconv` will be below 1. However, it may also exceed 1 if the number of exonerated suspects is exceeded by the number of suspects convicted of multiple charges. (See **[here](https://www.michigancriminallawyer-blog.com/2014/08/this-blog-is-based-upon.html)** for examples of multiple charges stemming from a single arrest.)

The notes on `prbarr` indicate _the probability of arrest is proxied by the ratio of arrests to offenses..._. If multiple suspects are arrested for a single offense, and this happens more frequently than offenses which do not lead to arrests, `prbarr` would indeed exceed 1.

In both cases, there are plausible explanations for the values we observe. Therefore we will not drop these records from our dataset. We will, however, subject them to further scrutiny.

```{r plausibility_checks, echo = FALSE, results = "hide", fig.show = "hide"}
plot(density(crime_na$year)) # TS: Confirmed all 1987
plot(density(crime_na$crmrte)) # TS: Confirmed all positive
plot(density(crime_na$prbarr)) # TS: Confirmed all positive
plot(density(crime_na$prbconv)) # TS: Confirmed all positive
plot(density(crime_na$prbpris)) # TS: Confirmed all positive
plot(density(crime_na$avgsen)) # TS: Confirmed all positive
plot(density(crime_na$polpc)) # TS: Confirmed all positive; in boxplot, 1 outlier
plot(density(crime_na$density)) # TS: Confirmed all positive; in boxplot, 8 outliers
plot(density(crime_na$taxpc)) # TS: Confirmed all positive; in boxplot, several outliers
plot(density(crime_na$west)) # TS: Confirmed all either 0 or 1
plot(density(crime_na$central)) # TS: Confirmed all either 0 or 1
plot(density(crime_na$urban)) # TS: Confirmed all either 0 or 1
plot(density(crime_na$pctmin80)) # TS: Confirmed all positive, between 0 and 100
plot(density(crime_na$wcon))
plot(density(crime_na$wtuc))
plot(density(crime_na$wtrd))
plot(density(crime_na$wfir))
plot(density(crime_na$wser)) # TS: Some serious outliers at > $2000
plot(density(crime_na$wmfg))
plot(density(crime_na$wsta))
plot(density(crime_na$wloc))
plot(density(crime_na$mix))
```

Examining the remainder of our data, we found no substantial evidence of _top-coded_ or _bottom-coded_ (i.e., truncated) variables which might bias our regression models. However, there is an extreme outlier in `wser`, the variable indicating the county's weekly wage in the service industry.

# Research Question and Model-Building

Our **research question** is the following: _What enforcement policies should our candidate endorse to reduce crime rates?_

We face a key limitation: our data does not give us visibility into crime, it only gives us insight into the official _crime rate_. The crime rate is a function not only of crimes committed but also of various factors, some of which may be unobservable. For instance, poor community-police relations may bias crime rates downward if an area's residents **[do not report all the crimes they observe or experience](https://www.washingtonpost.com/news/acts-of-faith/wp/2018/04/19/churches-make-a-drastic-pledge-in-the-name-of-social-justice-to-stop-calling-the-police/?utm_term=.ac2ea8ee1523)**. Conversely, those poor relations may also bias crime rates upward if police officers engage in **[predatory policing practices](https://www.huffingtonpost.com/2015/05/04/st-louis-county-predatory-policing_n_7201964.html)** and the community lacks the wherewithal to fight back. As we report our findings we will make note of potential bias that results from our inability to observe and analyze critical variables.

## New Variable Creation

All together there are 9 wage variables, each representing a different sector/industry.  There is no reason to believe that a single industry might contribute disproportionately to crime, but there is reason to assume a priori that low wage levels in general might create an environment in which crime incidence increases.  Including all 9 variables when our dataset only contains 90 observations would be extremely limiting, but excluding them entirely prohbits us from understanding how micro economic conditions contribute to crime.  Our first thought was to research the composition of each county's economy, and then weight each variable accordingly; unfortunately, this data lies outside the scope of this research.  The solution we ultimately implemented was to create three (3) new variables:

  1) Gov't Wage: Average of wfed (Federal wage), wsta (State wage), and wloc (local wage)
  2) Physical Labor Wage: Average of wmfg (Manufacturing), wser (Service), wcon (Construction)
  3) Industry Wage: Average of wfir (Finance/Investment/Real Estate), wtrd (Wholesale/Retail Trade), and wtuc          (Transportation, Utilities, Communication)
  

``` {r new_variable_creation}
crime_na$govt_wg <- (crime_na$wfed+crime_na$wsta+crime_na$wloc)/3
crime_na$physical_wg <- (crime_na$wmfg+crime_na$wser+crime_na$wcon)/3
crime_na$industry_wg <- (crime_na$wfir+crime_na$wtrd+crime_na$wtuc)/3

```

## Explanatory variables of interest

The table below details several main variables of interest we will use to build and refine our model.

\begin{center} % https://community.rstudio.com/t/inserting-table-in-r-markdown/7260/4
\captionof{table}{Hypothesized Primary Determinants of Observed Crime Rate}
\begin{tabular}{|l|l|p{7cm}|p{2cm}|}
\hline
Variable Name & Explanation & Reasoning & Transformation Applied \\ \hhline{|=|=|=|=|}
\texttt{polpc} & \textit{police per capita} & Police may act as a deterrent to crime, may increase the observed crime rate, or both. & <none> \\
\texttt{pctymle} & \textit{percent young male} & Young males commit and are charged with a disproportionate share of crimes & <none> \\
\texttt{density} & \textit{people per sq. mile} & Greater population density increases opportunity for crimes to be committed and reported & <none> \\
\texttt{taxpc} & \textit{tax revenue per capita} & Lower tax revenues may be associated with poorer community-government relations, greater economic hardship, and less policing \footnote{This may introduce collinearity with several other variables} & $log_{10}$  \\
\texttt{prbarr} & \textit{`probability' of arrest} & Greater probability of arrest may serve a deterrent function & <none> \\
\texttt{prbconv} & \textit{`probability' of conviction} & Greater probability of conviction may serve a deterrent function & <none> \\
\texttt{prbpris} & \textit{`probability' of prison sentence} & Greater probability of sentencing may serve a deterrent function & <none> \\
\texttt{avgsen} & \textit{average sentence, in days} & Harsher sentencing practices may serve a deterrent function & <none> \\
\texttt{pctmin80} & \textit{percent minority in 1980} & Minorities are disproportionately arrested and convicted of crimes & <none> \\
\hline
\end{tabular}
\end{center}

\[
%\begin{table}[!h]
%\centering
%\caption{Hypothesized Primary Determinants of Observed Crime Rate}
%\label{pntable}
%%\begin{tabular}{l>{\raggedright\arraybackslash$}p{2cm}>{$}|l|c}
%\begin{tabular}{p{1.5cm} | >{\raggedright}p{3cm} | p{8cm} | p{2cm}}
%\toprule
%\centering\textbf{Variable Name} & \centering\textbf{Explanation} & \centering\textbf{Reasoning} & \centering\textbf{Transformation Applied} & \\
%\midrule
%\texttt{polpc} & \textit{police per capita} & Police may act as a deterrent to crime, may increase the observed crime rate, or both. & <none> \\
%\texttt{pctymle} & \textit{percent young male} & Young males commit and are charged with a disproportionate share of crimes & <none> \\
%\texttt{density} & \textit{people per sq. mile} & Greater population density increases opportunity for crimes to be committed and reported & <none> \\
%\texttt{taxpc} & \textit{tax revenue per capita} & Lower tax revenues may be associated with poorer community-government relations, greater economic hardship, and less policing \footnote{This may introduce collinearity with several other variables} & $log_{10}$  \\
%\texttt{prbarr} & \textit{`probability' of arrest} & Greater probability of arrest may serve a deterrent function & <none> \\
%\texttt{prbconv} & \textit{`probability' of conviction} & Greater probability of conviction may serve a deterrent function & <none> \\
%\texttt{prbpris} & \textit{`probability' of prison sentence} & Greater probability of sentencing may serve a deterrent function & <none> \\
%\texttt{avgsen} & \textit{average sentence, in days} & Harsher sentencing practices may serve a deterrent function & <none> \\
%\texttt{pctmin80} & \textit{percent minority in 1980} & Minorities are disproportionately arrested and convicted of crimes & <none> \\
%\bottomrule
%\end{tabular}
%\end{table}
\]

In order to answer our research question we created a model which included variables related to key crime policy decisions.  We only included variables which would allow our cnadidate to make concrete policy proposals that lie within her purview.

Using the aforementioned criteria we choose the variables police per capita (polpc), probability of arrest (prbarr), probability of conviction (prbconv), probability of incarceration, and average sentence length for our first model.  Understanding how these items relate to crime rate can help shape her position, and understand whether a "Tough on Crime" stance does in fact acheive a reduction in crime.

``` {r model 1}
model1 <- with(crime_na, lm(crmrte ~ polpc+prbarr+prbconv+prbpris+avgsen))
model1$AIC <- AIC(model1)
summary(model1)
```

Comments on Model 1:

Police per capita, probability of arrest, and probability of conviction all have high levels of significance, and the overall model has an adjusted R squared of .5232.  There are three main points to highlight:

  1) Our coefficient for police per capita (polpc) is positive, large, and highly significant. If we assume this model to be causal then the best mechanism for reducing crime rates would be to sunset the police force!  What is most likely happening is that police per capita is a response to criminal activity.  
  
  2) Both probability of arrest and probability of conviction have highly significant and negative coefficients.  This fits with what we would expect: The more likely an individual is to be caught and convicted the less likely they are to commit crime.
  
  3) Probability of incarceration and average sentence length are not statistically significant.  Furthermore, the coefficient for incarceration rate is positive, which is counterintuitive. 

## Model 2


While our first model showed promise there are a range of factors which might be correlated with these explantory variables leading to multicollinearity issues.  In order to control for this we created a second model which includes variables we believe to be highly correlated with our three key variables.

Police Per Capita:  The police force is funded by taxpayers, and therefore we might expect higher levels of police to be correlated with higher levels of revenue.  Given the assumed diminishing marginal returns of money it makes sense to include the log transformation so that we can interpret our coefficient as the change given a 1% increase.  Additionally, we would expect policing patterns to be very different in the city vis a vis suburban or rural areas, and therefore including density can help control for this.

Probability of Arrest: Outside research suggests that that men, and especially minority men are at an increased risk of being arrested.  Therefore we will include both the percent male and percent minority variables.

Probability of Conviction:  This process involves lawyers, judges, police, and many other government officials.  This probability might be correlated to the overall quality of those departements which can be proxied by our government wage variable.

Probability Incarceration and Average sentencing may also be correlated with the additional included variables, but there aren't any additional covariates we included on their behalf.

  
``` {r model 2}
model2 <- with(crime_na, lm(crmrte ~ polpc+prbarr+prbconv+prbpris+avgsen+log(taxpc, base = 10)+density+govt_wg+pctymle+pctmin80))
model2$AIC <- AIC(model2)
summary(model2)
```

Notes on Model 2:



## Model 3

Given the countless ways behavioral issues are interconnected, we wondered whether every variable we had data on was correlated with either crime rate or an already included variable in some fashion.  Our focus was to determine if including all our variables substantially changed the significance or corefficient of any of our previously included variables.  Additionally, we wanted to understand if any of the variables we had previously left out were in fact predictive overall. 

``` {r model 3}
model3 <- with(crime_na, lm(crmrte ~ polpc+prbarr+prbconv+prbpris+avgsen+log(taxpc, base = 10)+density+govt_wg+pctymle+pctmin80+west+central+urban+physical_wg+industry_wg+mix))
model3$AIC <- AIC(model3)
summary(model3)
```

Model 3 Notes:



```{r stargazer, results = "asis"}
# Code from here: https://stackoverflow.com/questions/47494761/show-akaike-criteria-in-stargazer (using the example 2 approach)
stargazer(model1, model2, model3,
          type = "latex", report="vc", header=FALSE,
          title = "Linear Models Predicting Crime Rate",
          keep.stat = c("aic", "rsq", "n"), omit.table.layout = "n")


```


## Findings and Policy Recommendations

## Conclusion
